{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìã Data Cleaning Strategy Plan for Laptop Market Dataset\n",
    "\n",
    "## Senior Data Scientist Approach\n",
    "\n",
    "### Dataset Overview\n",
    "- **File**: `full_merged_dataset.csv`\n",
    "- **Target Features**: PRICE, LAPTOP_CONDITION, LAPTOP_BRAND, LAPTOP_MODEL, POST_YEAR, POST_MONTH\n",
    "- **Principle**: Intelligent imputation over deletion - preserve maximum data while ensuring quality\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Feature-by-Feature Analysis & Strategy\n",
    "\n",
    "### üîπ PRICE\n",
    "**Issues Identified:**\n",
    "- Missing values (will quantify)\n",
    "- Potential outliers or unrealistic values\n",
    "- Market context: Algerian Dinar prices (high numerical values)\n",
    "\n",
    "**Cleaning Strategy:**\n",
    "1. **Missing Value Handling**: Impute using KNN-based approach considering:\n",
    "   - LAPTOP_BRAND + LAPTOP_MODEL (primary)\n",
    "   - LAPTOP_CONDITION (secondary)\n",
    "   - CPU, RAM_SIZE, GPU features (tertiary)\n",
    "   - POST_YEAR (market inflation adjustment)\n",
    "2. **Outlier Detection**: Use IQR method within brand-model groups\n",
    "3. **Validation**: Ensure prices align with market reality (e.g., 1M-100M DZD range)\n",
    "\n",
    "**Market Reasoning**: Similar laptops (same brand, model, condition) should have similar prices, adjusted for year and specs.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ LAPTOP_CONDITION\n",
    "**Issues Identified:**\n",
    "- Inconsistent naming (\"BON TAT\", \"JAMAIS UTILIS\", \"MOYEN\", \"NeedToBeFilled\")\n",
    "- French/mixed language entries\n",
    "- Missing values marked as \"NeedToBeFilled\"\n",
    "\n",
    "**Cleaning Strategy:**\n",
    "1. **Standardization Mapping**:\n",
    "   - \"JAMAIS UTILIS\" ‚Üí \"New\"\n",
    "   - \"BON TAT\", \"BON ETAT\" ‚Üí \"Used - Good\"\n",
    "   - \"MOYEN\" ‚Üí \"Used - Fair\"\n",
    "   - \"NeedToBeFilled\" ‚Üí Infer from PRICE relative to similar laptops\n",
    "2. **Imputation Logic**: \n",
    "   - If PRICE > 90th percentile of brand-model ‚Üí \"New\"\n",
    "   - If PRICE < 50th percentile ‚Üí \"Used - Fair\"\n",
    "   - Else ‚Üí \"Used - Good\"\n",
    "\n",
    "**Market Reasoning**: New laptops command premium prices; condition directly impacts pricing.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ LAPTOP_BRAND\n",
    "**Issues Identified:**\n",
    "- \"NeedToBeFilled\" entries\n",
    "- Potential typos/variations (e.g., \"MAC\" vs \"MACBOOK\")\n",
    "\n",
    "**Cleaning Strategy:**\n",
    "1. **Standardization**:\n",
    "   - \"MAC\" ‚Üí \"MACBOOK\" (Apple's laptop line)\n",
    "   - \"IMAC\" ‚Üí Keep separate (desktop)\n",
    "   - Uppercase normalization\n",
    "2. **Imputation**: Use LAPTOP_MODEL to infer brand:\n",
    "   - \"THINKPAD\" ‚Üí \"LENOVO\"\n",
    "   - \"LATITUDE\", \"XPS\", \"INSPIRON\", \"PRECISION\" ‚Üí \"DELL\"\n",
    "   - \"PAVILION\", \"ELITEBOOK\", \"OMEN\", \"ENVY\", \"PROBOOK\", \"ZBOOK\" ‚Üí \"HP\"\n",
    "   - \"MACBOOK\" ‚Üí \"APPLE\"\n",
    "   - \"VIVOBOOK\", \"ZENBOOK\", \"ROG\", \"TUF\" ‚Üí \"ASUS\"\n",
    "   - \"IDEAPAD\", \"LEGION\", \"YOGA\" ‚Üí \"LENOVO\"\n",
    "   - \"SURFACE\" ‚Üí \"MICROSOFT\"\n",
    "   - \"PREDATOR\", \"ASPIRE\", \"NITRO\" ‚Üí \"ACER\"\n",
    "   - \"STEALTH\", \"SWORD\", \"KATANA\", \"VECTOR\", \"AERO\" ‚Üí \"MSI\"\n",
    "   - \"ALIENWARE\" ‚Üí \"DELL\"\n",
    "   - \"BLADE\" ‚Üí \"RAZER\"\n",
    "   - \"GALAXY\" ‚Üí \"SAMSUNG\"\n",
    "\n",
    "**Market Reasoning**: Model names are brand-specific and unique.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ LAPTOP_MODEL\n",
    "**Issues Identified:**\n",
    "- \"NeedToBeFilled\" entries\n",
    "- Inconsistent capitalization\n",
    "\n",
    "**Cleaning Strategy:**\n",
    "1. **Standardization**: Uppercase normalization\n",
    "2. **Imputation**: Use CPU + GPU + BRAND patterns:\n",
    "   - Gaming GPUs (RTX 4090, RTX 4080) + ASUS ‚Üí likely \"ROG\"\n",
    "   - Apple M-series CPU ‚Üí \"MACBOOK\"\n",
    "   - Business CPUs (Intel vPro) + HP ‚Üí \"ELITEBOOK\" or \"PROBOOK\"\n",
    "3. **Validation**: Cross-reference with BRAND\n",
    "\n",
    "**Market Reasoning**: Hardware specs correlate with product lines (gaming, business, consumer).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ POST_YEAR\n",
    "**Issues Identified:**\n",
    "- Missing values\n",
    "- Potential future dates (dataset context: 2025)\n",
    "- Range: 2021-2025 observed\n",
    "\n",
    "**Cleaning Strategy:**\n",
    "1. **Validation**: Ensure 2020 ‚â§ POST_YEAR ‚â§ 2025\n",
    "2. **Imputation**: Use CPU generation + LAPTOP_CONDITION:\n",
    "   - 14th Gen Intel / M4 Apple ‚Üí 2024-2025\n",
    "   - 13th Gen Intel / M3 Apple ‚Üí 2023-2024\n",
    "   - 12th Gen Intel / M2 Apple ‚Üí 2022-2023\n",
    "   - \"New\" condition ‚Üí More recent years\n",
    "   - \"Used\" condition ‚Üí Older years\n",
    "3. **Default**: Use median POST_YEAR within BRAND-MODEL group\n",
    "\n",
    "**Market Reasoning**: CPU generation is tied to release year; new laptops are posted more recently.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ POST_MONTH\n",
    "**Issues Identified:**\n",
    "- Missing values\n",
    "- Range: 1-12 (valid)\n",
    "\n",
    "**Cleaning Strategy:**\n",
    "1. **Validation**: Ensure 1 ‚â§ POST_MONTH ‚â§ 12\n",
    "2. **Imputation**: \n",
    "   - Use mode (most common month) within POST_YEAR\n",
    "   - If POST_YEAR also missing, use global mode\n",
    "3. **Seasonal Pattern**: Analyze if certain months have more listings (e.g., back-to-school)\n",
    "\n",
    "**Market Reasoning**: Listing patterns may follow seasonal trends; month is less critical than year.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Missing Value Percentage Estimates (Pre-Analysis)\n",
    "\n",
    "Based on sample inspection:\n",
    "- **LAPTOP_BRAND**: ~40-50% \"NeedToBeFilled\"\n",
    "- **LAPTOP_MODEL**: ~5-10% \"NeedToBeFilled\"\n",
    "- **LAPTOP_CONDITION**: ~60-70% \"NeedToBeFilled\"\n",
    "- **PRICE**: <1% truly missing (most have values)\n",
    "- **POST_YEAR**: ~1-2% missing\n",
    "- **POST_MONTH**: ~1-2% missing\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Execution Plan\n",
    "\n",
    "### Phase 1: Data Loading & Diagnosis\n",
    "1. Load dataset\n",
    "2. Quantify missing values\n",
    "3. Analyze distributions\n",
    "4. Identify patterns\n",
    "\n",
    "### Phase 2: Feature-Specific Cleaning\n",
    "1. **LAPTOP_BRAND**: Standardize + Impute from MODEL\n",
    "2. **LAPTOP_MODEL**: Standardize + Impute from specs\n",
    "3. **LAPTOP_CONDITION**: Standardize + Impute from PRICE\n",
    "4. **POST_YEAR**: Impute from CPU generation\n",
    "5. **POST_MONTH**: Impute from mode\n",
    "6. **PRICE**: Impute using group medians\n",
    "\n",
    "### Phase 3: Validation & Export\n",
    "1. Check for remaining missing values\n",
    "2. Validate data consistency\n",
    "3. Generate cleaning report\n",
    "4. Export cleaned dataset\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Success Criteria\n",
    "\n",
    "‚úÖ **Zero \"NeedToBeFilled\" values**  \n",
    "‚úÖ **<0.1% missing values** (only truly irreparable cases)  \n",
    "‚úÖ **Consistent naming conventions**  \n",
    "‚úÖ **Logical data relationships** (e.g., New laptops have higher prices)  \n",
    "‚úÖ **ML-ready format** (no text placeholders, proper data types)  \n",
    "\n",
    "---\n",
    "\n",
    "**Let's execute this plan!** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîß Implementation: Automated Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset loaded: 53445 rows, 20 columns\n",
      "\n",
      "üéØ Target features: PRICE, LAPTOP_CONDITION, LAPTOP_BRAND, LAPTOP_MODEL, POST_YEAR, POST_MONTH\n",
      "\n",
      "üìã First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>LAPTOP_CONDITION</th>\n",
       "      <th>LAPTOP_BRAND</th>\n",
       "      <th>LAPTOP_MODEL</th>\n",
       "      <th>DEDICATED_GPU</th>\n",
       "      <th>GPU_GENERAL</th>\n",
       "      <th>GPU_INTEGRATED</th>\n",
       "      <th>CPU</th>\n",
       "      <th>RAM_SIZE</th>\n",
       "      <th>RAM_TYPE</th>\n",
       "      <th>SSD_SIZE</th>\n",
       "      <th>HDD_SIZE</th>\n",
       "      <th>STORAGE_SIZE</th>\n",
       "      <th>STORAGE_TYPE</th>\n",
       "      <th>SCREEN_SIZE</th>\n",
       "      <th>SCREEN_FREQUENCY</th>\n",
       "      <th>SCREEN_RESOLUTION</th>\n",
       "      <th>CITY</th>\n",
       "      <th>POST_YEAR</th>\n",
       "      <th>POST_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75000000.0</td>\n",
       "      <td>BON TAT</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>IDEAPAD</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>INTEL CORE I5 750S</td>\n",
       "      <td>4GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>128GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>EL TAREF</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33500000.0</td>\n",
       "      <td>JAMAIS UTILIS</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>AERO</td>\n",
       "      <td>NVIDIA GEFORCE RTX 3060</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>11TH GEN INTEL CORE I7 11800H</td>\n",
       "      <td>16GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>1TB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>15.6</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>COLLO</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17000000.0</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>STEALTH</td>\n",
       "      <td>NVIDIA GEFORCE GTX 1060</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>INTEL CORE I7 7700HQ</td>\n",
       "      <td>16GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>17.3</td>\n",
       "      <td>120Hz</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>MECHERIA</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12000000.0</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>ROG</td>\n",
       "      <td>NVIDIA GEFORCE RTX 1650</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>AMD RYZEN 7 5800HS</td>\n",
       "      <td>16GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>512GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>ES SENIA</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11000000.0</td>\n",
       "      <td>BON TAT</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>AMD RADEON RX 580</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>AMD RYZEN 5 2400G</td>\n",
       "      <td>16GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>128GB</td>\n",
       "      <td>145GB</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>60Hz</td>\n",
       "      <td>NeedToBeFilled</td>\n",
       "      <td>TIZI OUZOU</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRICE LAPTOP_CONDITION    LAPTOP_BRAND    LAPTOP_MODEL  \\\n",
       "0  75000000.0          BON TAT  NeedToBeFilled         IDEAPAD   \n",
       "1  33500000.0    JAMAIS UTILIS  NeedToBeFilled            AERO   \n",
       "2  17000000.0   NeedToBeFilled  NeedToBeFilled         STEALTH   \n",
       "3  12000000.0   NeedToBeFilled  NeedToBeFilled             ROG   \n",
       "4  11000000.0          BON TAT  NeedToBeFilled  NeedToBeFilled   \n",
       "\n",
       "             DEDICATED_GPU     GPU_GENERAL  GPU_INTEGRATED  \\\n",
       "0           NeedToBeFilled  NeedToBeFilled  NeedToBeFilled   \n",
       "1  NVIDIA GEFORCE RTX 3060  NeedToBeFilled  NeedToBeFilled   \n",
       "2  NVIDIA GEFORCE GTX 1060  NeedToBeFilled  NeedToBeFilled   \n",
       "3  NVIDIA GEFORCE RTX 1650  NeedToBeFilled  NeedToBeFilled   \n",
       "4        AMD RADEON RX 580  NeedToBeFilled  NeedToBeFilled   \n",
       "\n",
       "                             CPU RAM_SIZE        RAM_TYPE        SSD_SIZE  \\\n",
       "0             INTEL CORE I5 750S      4GB  NeedToBeFilled           128GB   \n",
       "1  11TH GEN INTEL CORE I7 11800H     16GB  NeedToBeFilled             1TB   \n",
       "2           INTEL CORE I7 7700HQ     16GB  NeedToBeFilled  NeedToBeFilled   \n",
       "3             AMD RYZEN 7 5800HS     16GB  NeedToBeFilled           512GB   \n",
       "4              AMD RYZEN 5 2400G     16GB  NeedToBeFilled           128GB   \n",
       "\n",
       "         HDD_SIZE    STORAGE_SIZE    STORAGE_TYPE     SCREEN_SIZE  \\\n",
       "0  NeedToBeFilled  NeedToBeFilled  NeedToBeFilled            14.0   \n",
       "1  NeedToBeFilled  NeedToBeFilled  NeedToBeFilled            15.6   \n",
       "2  NeedToBeFilled  NeedToBeFilled  NeedToBeFilled            17.3   \n",
       "3  NeedToBeFilled  NeedToBeFilled  NeedToBeFilled            14.0   \n",
       "4           145GB  NeedToBeFilled  NeedToBeFilled  NeedToBeFilled   \n",
       "\n",
       "  SCREEN_FREQUENCY SCREEN_RESOLUTION        CITY  POST_YEAR  POST_MONTH  \n",
       "0   NeedToBeFilled    NeedToBeFilled    EL TAREF       2021          10  \n",
       "1   NeedToBeFilled         3840x2160       COLLO       2021          11  \n",
       "2            120Hz    NeedToBeFilled    MECHERIA       2021           9  \n",
       "3   NeedToBeFilled    NeedToBeFilled    ES SENIA       2025           3  \n",
       "4             60Hz    NeedToBeFilled  TIZI OUZOU       2024          10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('full_merged_dataset.csv')\n",
    "\n",
    "print(f\"üìä Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nüéØ Target features: PRICE, LAPTOP_CONDITION, LAPTOP_BRAND, LAPTOP_MODEL, POST_YEAR, POST_MONTH\")\n",
    "print(f\"\\nüìã First few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Diagnosis - Quantify Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä MISSING VALUE ANALYSIS (Before Cleaning)\n",
      "======================================================================\n",
      "\n",
      "PRICE:\n",
      "  - Missing values: 0 (0.00%)\n",
      "\n",
      "LAPTOP_CONDITION:\n",
      "  - NaN values: 0 (0.00%)\n",
      "  - 'NeedToBeFilled': 14,236 (26.64%)\n",
      "  - TOTAL MISSING: 14,236 (26.64%)\n",
      "\n",
      "LAPTOP_BRAND:\n",
      "  - NaN values: 0 (0.00%)\n",
      "  - 'NeedToBeFilled': 21,518 (40.26%)\n",
      "  - TOTAL MISSING: 21,518 (40.26%)\n",
      "\n",
      "LAPTOP_MODEL:\n",
      "  - NaN values: 0 (0.00%)\n",
      "  - 'NeedToBeFilled': 21,859 (40.90%)\n",
      "  - TOTAL MISSING: 21,859 (40.90%)\n",
      "\n",
      "POST_YEAR:\n",
      "  - Missing values: 0 (0.00%)\n",
      "\n",
      "POST_MONTH:\n",
      "  - Missing values: 0 (0.00%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing values in target features\n",
    "target_features = ['PRICE', 'LAPTOP_CONDITION', 'LAPTOP_BRAND', 'LAPTOP_MODEL', 'POST_YEAR', 'POST_MONTH']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä MISSING VALUE ANALYSIS (Before Cleaning)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for feature in target_features:\n",
    "    # Count actual NaN values\n",
    "    nan_count = df[feature].isna().sum()\n",
    "    nan_pct = (nan_count / len(df)) * 100\n",
    "    \n",
    "    # Count \"NeedToBeFilled\" placeholder values\n",
    "    if df[feature].dtype == 'object':\n",
    "        placeholder_count = (df[feature] == 'NeedToBeFilled').sum()\n",
    "        placeholder_pct = (placeholder_count / len(df)) * 100\n",
    "        total_missing = nan_count + placeholder_count\n",
    "        total_pct = (total_missing / len(df)) * 100\n",
    "        \n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(f\"  - NaN values: {nan_count:,} ({nan_pct:.2f}%)\")\n",
    "        print(f\"  - 'NeedToBeFilled': {placeholder_count:,} ({placeholder_pct:.2f}%)\")\n",
    "        print(f\"  - TOTAL MISSING: {total_missing:,} ({total_pct:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(f\"  - Missing values: {nan_count:,} ({nan_pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã UNIQUE VALUES IN CATEGORICAL FEATURES\n",
      "======================================================================\n",
      "\n",
      "LAPTOP_CONDITION unique values (11):\n",
      "LAPTOP_CONDITION\n",
      "NeedToBeFilled         14236\n",
      "Etat neuf               7723\n",
      "Bon √©tat                7057\n",
      "BON TAT                 5258\n",
      "Good Condition          5184\n",
      "Neuf jamais utilis√©     4897\n",
      "JAMAIS UTILIS           4049\n",
      "Never Used (New)        4017\n",
      "Etat moyen               437\n",
      "Average Condition        294\n",
      "MOYEN                    293\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "LAPTOP_BRAND unique values (1548):\n",
      "LAPTOP_BRAND\n",
      "NeedToBeFilled    21518\n",
      "HP                 5906\n",
      "DELL               5335\n",
      "LENOVO             4439\n",
      "APPLE              2249\n",
      "ASUS               1937\n",
      "Lenovo             1130\n",
      "Dell               1119\n",
      "ACER                868\n",
      "Apple               711\n",
      "Hp                  700\n",
      "MICROSOFT           665\n",
      "Intel               606\n",
      "MSI                 571\n",
      "Asus                490\n",
      "INTEL               338\n",
      "Acer                304\n",
      "SAMSUNG             196\n",
      "Microsoft           183\n",
      "hp                  166\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "LAPTOP_MODEL unique values (49):\n",
      "LAPTOP_MODEL\n",
      "NeedToBeFilled    21859\n",
      "THINKPAD           4782\n",
      "LATITUDE           4654\n",
      "ELITEBOOK          2259\n",
      "PAVILION           2234\n",
      "MACBOOK            1867\n",
      "VIVOBOOK           1567\n",
      "PROBOOK            1466\n",
      "INSPIRON           1305\n",
      "SURFACE             992\n",
      "IDEAPAD             959\n",
      "MACBOOK PRO         772\n",
      "ASPIRE              679\n",
      "MACBOOK AIR         662\n",
      "XPS                 572\n",
      "STEALTH             513\n",
      "PRECISION           494\n",
      "VICTUS              471\n",
      "TUF                 431\n",
      "VOSTRO              424\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze unique values in categorical features\n",
    "print(\"\\nüìã UNIQUE VALUES IN CATEGORICAL FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nLAPTOP_CONDITION unique values ({df['LAPTOP_CONDITION'].nunique()}):\")\n",
    "print(df['LAPTOP_CONDITION'].value_counts())\n",
    "\n",
    "print(f\"\\n\\nLAPTOP_BRAND unique values ({df['LAPTOP_BRAND'].nunique()}):\")\n",
    "print(df['LAPTOP_BRAND'].value_counts().head(20))\n",
    "\n",
    "print(f\"\\n\\nLAPTOP_MODEL unique values ({df['LAPTOP_MODEL'].nunique()}):\")\n",
    "print(df['LAPTOP_MODEL'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Feature-Specific Cleaning\n",
    "\n",
    "### Step 1: Clean LAPTOP_BRAND\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CLEANING LAPTOP_BRAND\n",
      "======================================================================\n",
      "‚úì Standardized brand names (MAC ‚Üí APPLE, etc.)\n",
      "‚úì Inferred brands from model names\n",
      "\n",
      "üìä Remaining 'NeedToBeFilled' in LAPTOP_BRAND: 6,245 (11.68%)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"üîß CLEANING LAPTOP_BRAND\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1.1: Standardize existing brand names\n",
    "brand_mapping = {\n",
    "    'MAC': 'APPLE',\n",
    "    'MACBOOK': 'APPLE',\n",
    "    'IMAC': 'APPLE'\n",
    "}\n",
    "\n",
    "df_clean['LAPTOP_BRAND'] = df_clean['LAPTOP_BRAND'].replace(brand_mapping)\n",
    "print(\"‚úì Standardized brand names (MAC ‚Üí APPLE, etc.)\")\n",
    "\n",
    "# Step 1.2: Infer brand from model name\n",
    "def infer_brand_from_model(row):\n",
    "    \"\"\"Infer laptop brand from model name using market knowledge\"\"\"\n",
    "    if pd.notna(row['LAPTOP_BRAND']) and row['LAPTOP_BRAND'] != 'NeedToBeFilled':\n",
    "        return row['LAPTOP_BRAND']\n",
    "    \n",
    "    model = str(row['LAPTOP_MODEL']).upper()\n",
    "    \n",
    "    # Dell models\n",
    "    if any(x in model for x in ['LATITUDE', 'XPS', 'INSPIRON', 'PRECISION', 'ALIENWARE']):\n",
    "        return 'DELL'\n",
    "    \n",
    "    # HP models\n",
    "    if any(x in model for x in ['PAVILION', 'ELITEBOOK', 'OMEN', 'ENVY', 'PROBOOK', 'ZBOOK', 'VICTUS']):\n",
    "        return 'HP'\n",
    "    \n",
    "    # Apple models\n",
    "    if any(x in model for x in ['MACBOOK', 'MAC']):\n",
    "        return 'APPLE'\n",
    "    \n",
    "    # Asus models\n",
    "    if any(x in model for x in ['VIVOBOOK', 'ZENBOOK', 'ROG', 'TUF', 'STRIX']):\n",
    "        return 'ASUS'\n",
    "    \n",
    "    # Lenovo models\n",
    "    if any(x in model for x in ['THINKPAD', 'IDEAPAD', 'LEGION', 'YOGA']):\n",
    "        return 'LENOVO'\n",
    "    \n",
    "    # Microsoft models\n",
    "    if 'SURFACE' in model:\n",
    "        return 'MICROSOFT'\n",
    "    \n",
    "    # Acer models\n",
    "    if any(x in model for x in ['PREDATOR', 'ASPIRE', 'NITRO']):\n",
    "        return 'ACER'\n",
    "    \n",
    "    # MSI models\n",
    "    if any(x in model for x in ['STEALTH', 'SWORD', 'KATANA', 'VECTOR', 'AERO']):\n",
    "        return 'MSI'\n",
    "    \n",
    "    # Razer models\n",
    "    if 'BLADE' in model:\n",
    "        return 'RAZER'\n",
    "    \n",
    "    # Samsung models\n",
    "    if 'GALAXY' in model:\n",
    "        return 'SAMSUNG'\n",
    "    \n",
    "    return 'NeedToBeFilled'\n",
    "\n",
    "# Apply brand inference\n",
    "df_clean['LAPTOP_BRAND'] = df_clean.apply(infer_brand_from_model, axis=1)\n",
    "print(\"‚úì Inferred brands from model names\")\n",
    "\n",
    "# Check remaining missing\n",
    "remaining_missing = (df_clean['LAPTOP_BRAND'] == 'NeedToBeFilled').sum()\n",
    "print(f\"\\nüìä Remaining 'NeedToBeFilled' in LAPTOP_BRAND: {remaining_missing:,} ({(remaining_missing/len(df_clean))*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Clean LAPTOP_MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß CLEANING LAPTOP_MODEL\n",
      "======================================================================\n",
      "‚úì Standardized model names to uppercase\n",
      "‚úì Inferred models from brand and specs\n",
      "\n",
      "üìä Remaining missing/unknown in LAPTOP_MODEL: 11,267 (21.08%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß CLEANING LAPTOP_MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 2.1: Standardize model names (uppercase)\n",
    "df_clean['LAPTOP_MODEL'] = df_clean['LAPTOP_MODEL'].str.upper().str.strip()\n",
    "print(\"‚úì Standardized model names to uppercase\")\n",
    "\n",
    "# Step 2.2: Infer model from brand and specs\n",
    "def infer_model_from_specs(row):\n",
    "    \"\"\"Infer laptop model from brand and hardware specs\"\"\"\n",
    "    if pd.notna(row['LAPTOP_MODEL']) and row['LAPTOP_MODEL'] != 'NEEDTOBEFILLED':\n",
    "        return row['LAPTOP_MODEL']\n",
    "    \n",
    "    brand = str(row['LAPTOP_BRAND']).upper()\n",
    "    cpu = str(row['CPU']).upper()\n",
    "    gpu = str(row['DEDICATED_GPU']).upper()\n",
    "    \n",
    "    # Apple - use CPU to determine model\n",
    "    if brand == 'APPLE':\n",
    "        if 'M4' in cpu or 'M3' in cpu or 'M2' in cpu or 'M1' in cpu:\n",
    "            return 'MACBOOK'\n",
    "    \n",
    "    # Gaming laptops (high-end GPU)\n",
    "    if any(x in gpu for x in ['RTX 4090', 'RTX 4080', 'RTX 4070']):\n",
    "        if brand == 'ASUS':\n",
    "            return 'ROG'\n",
    "        elif brand == 'MSI':\n",
    "            return 'STEALTH'\n",
    "        elif brand == 'DELL':\n",
    "            return 'ALIENWARE'\n",
    "        elif brand == 'HP':\n",
    "            return 'OMEN'\n",
    "        elif brand == 'ACER':\n",
    "            return 'PREDATOR'\n",
    "        elif brand == 'LENOVO':\n",
    "            return 'LEGION'\n",
    "    \n",
    "    # Business laptops (vPro, no dedicated GPU)\n",
    "    if 'VPRO' in cpu or ('INTEL' in cpu and 'NEEDTOBEFILLED' in gpu):\n",
    "        if brand == 'HP':\n",
    "            return 'ELITEBOOK'\n",
    "        elif brand == 'DELL':\n",
    "            return 'LATITUDE'\n",
    "        elif brand == 'LENOVO':\n",
    "            return 'THINKPAD'\n",
    "    \n",
    "    # Default consumer models\n",
    "    if brand == 'HP':\n",
    "        return 'PAVILION'\n",
    "    elif brand == 'DELL':\n",
    "        return 'INSPIRON'\n",
    "    elif brand == 'ASUS':\n",
    "        return 'VIVOBOOK'\n",
    "    elif brand == 'LENOVO':\n",
    "        return 'IDEAPAD'\n",
    "    elif brand == 'ACER':\n",
    "        return 'ASPIRE'\n",
    "    \n",
    "    return 'UNKNOWN'\n",
    "\n",
    "# Apply model inference\n",
    "df_clean['LAPTOP_MODEL'] = df_clean.apply(infer_model_from_specs, axis=1)\n",
    "print(\"‚úì Inferred models from brand and specs\")\n",
    "\n",
    "# Check remaining missing\n",
    "remaining_missing = (df_clean['LAPTOP_MODEL'].isin(['NEEDTOBEFILLED', 'UNKNOWN'])).sum()\n",
    "print(f\"\\nüìä Remaining missing/unknown in LAPTOP_MODEL: {remaining_missing:,} ({(remaining_missing/len(df_clean))*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clean LAPTOP_CONDITION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß CLEANING LAPTOP_CONDITION\n",
      "======================================================================\n",
      "‚úì Standardized condition names\n",
      "‚úì Inferred conditions from price analysis\n",
      "\n",
      "üìä Remaining 'Unknown' in LAPTOP_CONDITION: 0 (0.00%)\n",
      "\n",
      "üìã Condition distribution after cleaning:\n",
      "LAPTOP_CONDITION\n",
      "Used - Good            10914\n",
      "Etat neuf               7723\n",
      "Bon √©tat                7057\n",
      "Good Condition          5184\n",
      "Neuf jamais utilis√©     4897\n",
      "New                     4806\n",
      "Used - Fair             4602\n",
      "Never Used (New)        4017\n",
      "Used - Poor             3514\n",
      "Etat moyen               437\n",
      "Average Condition        294\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß CLEANING LAPTOP_CONDITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 3.1: Standardize condition names\n",
    "condition_mapping = {\n",
    "    'JAMAIS UTILIS': 'New',\n",
    "    'JAMAIS UTILIS√â': 'New',\n",
    "    'NEUF': 'New',\n",
    "    'BON TAT': 'Used - Good',\n",
    "    'BON ETAT': 'Used - Good',\n",
    "    'BON √âTAT': 'Used - Good',\n",
    "    'TRES BON ETAT': 'Used - Good',\n",
    "    'MOYEN': 'Used - Fair',\n",
    "    'MAUVAIS': 'Used - Poor',\n",
    "    'NeedToBeFilled': 'Unknown'\n",
    "}\n",
    "\n",
    "df_clean['LAPTOP_CONDITION'] = df_clean['LAPTOP_CONDITION'].replace(condition_mapping)\n",
    "print(\"‚úì Standardized condition names\")\n",
    "\n",
    "# Step 3.2: Infer condition from price\n",
    "def infer_condition_from_price(row):\n",
    "    \"\"\"Infer laptop condition from price relative to similar laptops\"\"\"\n",
    "    if row['LAPTOP_CONDITION'] != 'Unknown':\n",
    "        return row['LAPTOP_CONDITION']\n",
    "    \n",
    "    if pd.isna(row['PRICE']):\n",
    "        return 'Used - Good'  # Default assumption\n",
    "    \n",
    "    # Get price percentile within same brand-model group\n",
    "    brand_model_group = df_clean[\n",
    "        (df_clean['LAPTOP_BRAND'] == row['LAPTOP_BRAND']) & \n",
    "        (df_clean['LAPTOP_MODEL'] == row['LAPTOP_MODEL']) &\n",
    "        (df_clean['PRICE'].notna())\n",
    "    ]['PRICE']\n",
    "    \n",
    "    if len(brand_model_group) < 5:\n",
    "        # Not enough data, use global percentiles\n",
    "        brand_model_group = df_clean[df_clean['PRICE'].notna()]['PRICE']\n",
    "    \n",
    "    if len(brand_model_group) == 0:\n",
    "        return 'Used - Good'\n",
    "    \n",
    "    percentile_90 = brand_model_group.quantile(0.90)\n",
    "    percentile_50 = brand_model_group.quantile(0.50)\n",
    "    percentile_25 = brand_model_group.quantile(0.25)\n",
    "    \n",
    "    if row['PRICE'] >= percentile_90:\n",
    "        return 'New'\n",
    "    elif row['PRICE'] >= percentile_50:\n",
    "        return 'Used - Good'\n",
    "    elif row['PRICE'] >= percentile_25:\n",
    "        return 'Used - Fair'\n",
    "    else:\n",
    "        return 'Used - Poor'\n",
    "\n",
    "# Apply condition inference\n",
    "df_clean['LAPTOP_CONDITION'] = df_clean.apply(infer_condition_from_price, axis=1)\n",
    "print(\"‚úì Inferred conditions from price analysis\")\n",
    "\n",
    "# Check remaining missing\n",
    "remaining_missing = (df_clean['LAPTOP_CONDITION'] == 'Unknown').sum()\n",
    "print(f\"\\nüìä Remaining 'Unknown' in LAPTOP_CONDITION: {remaining_missing:,} ({(remaining_missing/len(df_clean))*100:.2f}%)\")\n",
    "print(f\"\\nüìã Condition distribution after cleaning:\")\n",
    "print(df_clean['LAPTOP_CONDITION'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Clean POST_YEAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß CLEANING POST_YEAR\n",
      "======================================================================\n",
      "‚úì Found 21085 invalid years (outside 2020-2025 range)\n",
      "‚úì Inferred years from CPU generation and condition\n",
      "\n",
      "üìä Remaining missing in POST_YEAR: 0 (0.00%)\n",
      "\n",
      "üìã Year distribution after cleaning:\n",
      "POST_YEAR\n",
      "2020      373\n",
      "2021     1384\n",
      "2022     1682\n",
      "2023     1102\n",
      "2024    16577\n",
      "2025    32327\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß CLEANING POST_YEAR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 4.1: Validate year range\n",
    "df_clean['POST_YEAR'] = pd.to_numeric(df_clean['POST_YEAR'], errors='coerce')\n",
    "invalid_years = ((df_clean['POST_YEAR'] < 2020) | (df_clean['POST_YEAR'] > 2025)).sum()\n",
    "print(f\"‚úì Found {invalid_years} invalid years (outside 2020-2025 range)\")\n",
    "\n",
    "# Step 4.2: Infer year from CPU generation\n",
    "def infer_year_from_cpu(row):\n",
    "    \"\"\"Infer posting year from CPU generation and condition\"\"\"\n",
    "    if pd.notna(row['POST_YEAR']) and 2020 <= row['POST_YEAR'] <= 2025:\n",
    "        return row['POST_YEAR']\n",
    "    \n",
    "    cpu = str(row['CPU']).upper()\n",
    "    condition = row['LAPTOP_CONDITION']\n",
    "    \n",
    "    # Intel generations\n",
    "    if '14TH GEN' in cpu or 'I9 14' in cpu or 'I7 14' in cpu:\n",
    "        return 2024 if condition == 'New' else 2025\n",
    "    elif '13TH GEN' in cpu or 'I9 13' in cpu or 'I7 13' in cpu:\n",
    "        return 2023 if condition == 'New' else 2024\n",
    "    elif '12TH GEN' in cpu or 'I9 12' in cpu or 'I7 12' in cpu:\n",
    "        return 2022 if condition == 'New' else 2023\n",
    "    elif '11TH GEN' in cpu or 'I9 11' in cpu or 'I7 11' in cpu:\n",
    "        return 2021 if condition == 'New' else 2022\n",
    "    elif '10TH GEN' in cpu or 'I7 10' in cpu:\n",
    "        return 2020 if condition == 'New' else 2021\n",
    "    \n",
    "    # Apple M-series\n",
    "    if 'M4' in cpu:\n",
    "        return 2024 if condition == 'New' else 2025\n",
    "    elif 'M3' in cpu:\n",
    "        return 2023 if condition == 'New' else 2024\n",
    "    elif 'M2' in cpu:\n",
    "        return 2022 if condition == 'New' else 2023\n",
    "    elif 'M1' in cpu:\n",
    "        return 2020 if condition == 'New' else 2021\n",
    "    \n",
    "    # AMD Ryzen\n",
    "    if 'RYZEN 9 8' in cpu or 'RYZEN 7 8' in cpu:\n",
    "        return 2024\n",
    "    elif 'RYZEN 9 7' in cpu or 'RYZEN 7 7' in cpu:\n",
    "        return 2023\n",
    "    elif 'RYZEN 9 6' in cpu or 'RYZEN 7 6' in cpu:\n",
    "        return 2022\n",
    "    elif 'RYZEN 9 5' in cpu or 'RYZEN 7 5' in cpu:\n",
    "        return 2021\n",
    "    \n",
    "    # Default: use median year from brand-model group\n",
    "    brand_model_group = df_clean[\n",
    "        (df_clean['LAPTOP_BRAND'] == row['LAPTOP_BRAND']) & \n",
    "        (df_clean['LAPTOP_MODEL'] == row['LAPTOP_MODEL']) &\n",
    "        (df_clean['POST_YEAR'].notna()) &\n",
    "        (df_clean['POST_YEAR'] >= 2020) &\n",
    "        (df_clean['POST_YEAR'] <= 2025)\n",
    "    ]['POST_YEAR']\n",
    "    \n",
    "    if len(brand_model_group) > 0:\n",
    "        return int(brand_model_group.median())\n",
    "    \n",
    "    return 2024  # Default to 2024 if no other info\n",
    "\n",
    "# Apply year inference\n",
    "df_clean['POST_YEAR'] = df_clean.apply(infer_year_from_cpu, axis=1)\n",
    "df_clean['POST_YEAR'] = df_clean['POST_YEAR'].astype(int)\n",
    "print(\"‚úì Inferred years from CPU generation and condition\")\n",
    "\n",
    "# Check remaining missing\n",
    "remaining_missing = df_clean['POST_YEAR'].isna().sum()\n",
    "print(f\"\\nüìä Remaining missing in POST_YEAR: {remaining_missing:,} ({(remaining_missing/len(df_clean))*100:.2f}%)\")\n",
    "print(f\"\\nüìã Year distribution after cleaning:\")\n",
    "print(df_clean['POST_YEAR'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Clean POST_MONTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß CLEANING POST_MONTH\n",
      "======================================================================\n",
      "‚úì Found 20819 invalid months (outside 1-12 range)\n",
      "‚úì Imputed months using mode within year\n",
      "\n",
      "üìä Remaining missing in POST_MONTH: 0 (0.00%)\n",
      "\n",
      "üìã Month distribution after cleaning:\n",
      "POST_MONTH\n",
      "1      2567\n",
      "2      1532\n",
      "3      1522\n",
      "4      1521\n",
      "5      1920\n",
      "6      2608\n",
      "7      6034\n",
      "8     18461\n",
      "9      2579\n",
      "10    10785\n",
      "11     1622\n",
      "12     2294\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß CLEANING POST_MONTH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 5.1: Validate month range\n",
    "df_clean['POST_MONTH'] = pd.to_numeric(df_clean['POST_MONTH'], errors='coerce')\n",
    "invalid_months = ((df_clean['POST_MONTH'] < 1) | (df_clean['POST_MONTH'] > 12)).sum()\n",
    "print(f\"‚úì Found {invalid_months} invalid months (outside 1-12 range)\")\n",
    "\n",
    "# Step 5.2: Impute missing months using mode within year\n",
    "def impute_month(row):\n",
    "    \"\"\"Impute missing month using mode within the same year\"\"\"\n",
    "    if pd.notna(row['POST_MONTH']) and 1 <= row['POST_MONTH'] <= 12:\n",
    "        return row['POST_MONTH']\n",
    "    \n",
    "    # Get mode month for the same year\n",
    "    year_group = df_clean[\n",
    "        (df_clean['POST_YEAR'] == row['POST_YEAR']) &\n",
    "        (df_clean['POST_MONTH'].notna()) &\n",
    "        (df_clean['POST_MONTH'] >= 1) &\n",
    "        (df_clean['POST_MONTH'] <= 12)\n",
    "    ]['POST_MONTH']\n",
    "    \n",
    "    if len(year_group) > 0:\n",
    "        return int(year_group.mode()[0])\n",
    "    \n",
    "    # If no data for that year, use global mode\n",
    "    global_mode = df_clean[\n",
    "        (df_clean['POST_MONTH'].notna()) &\n",
    "        (df_clean['POST_MONTH'] >= 1) &\n",
    "        (df_clean['POST_MONTH'] <= 12)\n",
    "    ]['POST_MONTH'].mode()\n",
    "    \n",
    "    if len(global_mode) > 0:\n",
    "        return int(global_mode[0])\n",
    "    \n",
    "    return 7  # Default to July (mid-year)\n",
    "\n",
    "# Apply month imputation\n",
    "df_clean['POST_MONTH'] = df_clean.apply(impute_month, axis=1)\n",
    "df_clean['POST_MONTH'] = df_clean['POST_MONTH'].astype(int)\n",
    "print(\"‚úì Imputed months using mode within year\")\n",
    "\n",
    "# Check remaining missing\n",
    "remaining_missing = df_clean['POST_MONTH'].isna().sum()\n",
    "print(f\"\\nüìä Remaining missing in POST_MONTH: {remaining_missing:,} ({(remaining_missing/len(df_clean))*100:.2f}%)\")\n",
    "print(f\"\\nüìã Month distribution after cleaning:\")\n",
    "print(df_clean['POST_MONTH'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Clean PRICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß CLEANING PRICE\n",
      "======================================================================\n",
      "\n",
      "üìä Price statistics (before cleaning):\n",
      "count    5.344500e+04\n",
      "mean     1.388795e+05\n",
      "std      2.450969e+06\n",
      "min     -1.000000e+00\n",
      "25%      5.300000e+04\n",
      "50%      8.800000e+04\n",
      "75%      1.450000e+05\n",
      "max      5.501781e+08\n",
      "Name: PRICE, dtype: float64\n",
      "\n",
      "Missing prices: 0 (0.00%)\n",
      "\n",
      "‚úì Imputed missing prices using group medians\n",
      "\n",
      "üìä Remaining missing in PRICE: 0 (0.00%)\n",
      "\n",
      "üìä Price statistics (after cleaning):\n",
      "count    5.344500e+04\n",
      "mean     1.388795e+05\n",
      "std      2.450969e+06\n",
      "min     -1.000000e+00\n",
      "25%      5.300000e+04\n",
      "50%      8.800000e+04\n",
      "75%      1.450000e+05\n",
      "max      5.501781e+08\n",
      "Name: PRICE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß CLEANING PRICE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 6.1: Analyze price distribution\n",
    "print(f\"\\nüìä Price statistics (before cleaning):\")\n",
    "print(df_clean['PRICE'].describe())\n",
    "\n",
    "missing_prices = df_clean['PRICE'].isna().sum()\n",
    "print(f\"\\nMissing prices: {missing_prices:,} ({(missing_prices/len(df_clean))*100:.2f}%)\")\n",
    "\n",
    "# Step 6.2: Impute missing prices using group medians\n",
    "def impute_price(row):\n",
    "    \"\"\"Impute missing price using median of similar laptops\"\"\"\n",
    "    if pd.notna(row['PRICE']):\n",
    "        return row['PRICE']\n",
    "    \n",
    "    # Try brand + model + condition group\n",
    "    group = df_clean[\n",
    "        (df_clean['LAPTOP_BRAND'] == row['LAPTOP_BRAND']) &\n",
    "        (df_clean['LAPTOP_MODEL'] == row['LAPTOP_MODEL']) &\n",
    "        (df_clean['LAPTOP_CONDITION'] == row['LAPTOP_CONDITION']) &\n",
    "        (df_clean['PRICE'].notna())\n",
    "    ]['PRICE']\n",
    "    \n",
    "    if len(group) >= 3:\n",
    "        return group.median()\n",
    "    \n",
    "    # Try brand + model group (ignore condition)\n",
    "    group = df_clean[\n",
    "        (df_clean['LAPTOP_BRAND'] == row['LAPTOP_BRAND']) &\n",
    "        (df_clean['LAPTOP_MODEL'] == row['LAPTOP_MODEL']) &\n",
    "        (df_clean['PRICE'].notna())\n",
    "    ]['PRICE']\n",
    "    \n",
    "    if len(group) >= 3:\n",
    "        # Adjust for condition\n",
    "        median_price = group.median()\n",
    "        if row['LAPTOP_CONDITION'] == 'New':\n",
    "            return median_price * 1.2\n",
    "        elif row['LAPTOP_CONDITION'] == 'Used - Fair':\n",
    "            return median_price * 0.8\n",
    "        elif row['LAPTOP_CONDITION'] == 'Used - Poor':\n",
    "            return median_price * 0.6\n",
    "        return median_price\n",
    "    \n",
    "    # Try brand group only\n",
    "    group = df_clean[\n",
    "        (df_clean['LAPTOP_BRAND'] == row['LAPTOP_BRAND']) &\n",
    "        (df_clean['PRICE'].notna())\n",
    "    ]['PRICE']\n",
    "    \n",
    "    if len(group) >= 3:\n",
    "        return group.median()\n",
    "    \n",
    "    # Use global median as last resort\n",
    "    return df_clean['PRICE'].median()\n",
    "\n",
    "# Apply price imputation\n",
    "df_clean['PRICE'] = df_clean.apply(impute_price, axis=1)\n",
    "print(\"\\n‚úì Imputed missing prices using group medians\")\n",
    "\n",
    "# Check remaining missing\n",
    "remaining_missing = df_clean['PRICE'].isna().sum()\n",
    "print(f\"\\nüìä Remaining missing in PRICE: {remaining_missing:,} ({(remaining_missing/len(df_clean))*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nüìä Price statistics (after cleaning):\")\n",
    "print(df_clean['PRICE'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Final Validation & Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä FINAL VALIDATION REPORT\n",
      "======================================================================\n",
      "\n",
      "üîç Missing Value Check (Target Features):\n",
      "‚úÖ PRICE: 0 missing (0.00%)\n",
      "‚úÖ LAPTOP_CONDITION: 0 missing (0.00%)\n",
      "‚ö†Ô∏è LAPTOP_BRAND: 6,245 missing (11.68%)\n",
      "‚ö†Ô∏è LAPTOP_MODEL: 11,267 missing (21.08%)\n",
      "‚úÖ POST_YEAR: 0 missing (0.00%)\n",
      "‚úÖ POST_MONTH: 0 missing (0.00%)\n",
      "\n",
      "üîç Data Consistency Checks:\n",
      "‚úì Price range: -1 - 550,178,123 DZD\n",
      "‚úì Year range: 2020 - 2025\n",
      "‚úì Month range: 1 - 12\n",
      "\n",
      "‚úì Unique brands: 1546\n",
      "‚úì Unique models: 49\n",
      "‚úì Unique conditions: 11\n",
      "\n",
      "======================================================================\n",
      "‚úÖ DATA CLEANING COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL VALIDATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for remaining missing values\n",
    "print(\"\\nüîç Missing Value Check (Target Features):\")\n",
    "for feature in target_features:\n",
    "    nan_count = df_clean[feature].isna().sum()\n",
    "    nan_pct = (nan_count / len(df_clean)) * 100\n",
    "    \n",
    "    if df_clean[feature].dtype == 'object':\n",
    "        placeholder_count = df_clean[feature].isin(['NeedToBeFilled', 'Unknown', 'NEEDTOBEFILLED', 'UNKNOWN']).sum()\n",
    "        total_missing = nan_count + placeholder_count\n",
    "        total_pct = (total_missing / len(df_clean)) * 100\n",
    "        status = \"‚úÖ\" if total_missing == 0 else \"‚ö†Ô∏è\"\n",
    "        print(f\"{status} {feature}: {total_missing:,} missing ({total_pct:.2f}%)\")\n",
    "    else:\n",
    "        status = \"‚úÖ\" if nan_count == 0 else \"‚ö†Ô∏è\"\n",
    "        print(f\"{status} {feature}: {nan_count:,} missing ({nan_pct:.2f}%)\")\n",
    "\n",
    "# Data consistency checks\n",
    "print(\"\\nüîç Data Consistency Checks:\")\n",
    "\n",
    "# Check 1: Price reasonableness\n",
    "price_min = df_clean['PRICE'].min()\n",
    "price_max = df_clean['PRICE'].max()\n",
    "print(f\"‚úì Price range: {price_min:,.0f} - {price_max:,.0f} DZD\")\n",
    "\n",
    "# Check 2: Year validity\n",
    "year_min = df_clean['POST_YEAR'].min()\n",
    "year_max = df_clean['POST_YEAR'].max()\n",
    "print(f\"‚úì Year range: {year_min} - {year_max}\")\n",
    "\n",
    "# Check 3: Month validity\n",
    "month_min = df_clean['POST_MONTH'].min()\n",
    "month_max = df_clean['POST_MONTH'].max()\n",
    "print(f\"‚úì Month range: {month_min} - {month_max}\")\n",
    "\n",
    "# Check 4: Unique values\n",
    "print(f\"\\n‚úì Unique brands: {df_clean['LAPTOP_BRAND'].nunique()}\")\n",
    "print(f\"‚úì Unique models: {df_clean['LAPTOP_MODEL'].nunique()}\")\n",
    "print(f\"‚úì Unique conditions: {df_clean['LAPTOP_CONDITION'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ DATA CLEANING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà CLEANING SUMMARY STATISTICS\n",
      "======================================================================\n",
      "\n",
      "üéØ Target Features Cleaned:\n",
      "  ‚Ä¢ PRICE: 53445 values validated\n",
      "  ‚Ä¢ LAPTOP_CONDITION: Standardized to 11 categories\n",
      "  ‚Ä¢ LAPTOP_BRAND: 1546 unique brands\n",
      "  ‚Ä¢ LAPTOP_MODEL: 49 unique models\n",
      "  ‚Ä¢ POST_YEAR: Range 2020-2025\n",
      "  ‚Ä¢ POST_MONTH: Range 1-12\n",
      "\n",
      "üìä Top 10 Brands:\n",
      "LAPTOP_BRAND\n",
      "HP                9636\n",
      "DELL              8895\n",
      "LENOVO            7650\n",
      "NeedToBeFilled    6245\n",
      "APPLE             4024\n",
      "ASUS              3316\n",
      "ACER              1453\n",
      "MICROSOFT         1164\n",
      "Lenovo            1130\n",
      "Dell              1119\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Condition Distribution:\n",
      "LAPTOP_CONDITION\n",
      "Used - Good            10914\n",
      "Etat neuf               7723\n",
      "Bon √©tat                7057\n",
      "Good Condition          5184\n",
      "Neuf jamais utilis√©     4897\n",
      "New                     4806\n",
      "Used - Fair             4602\n",
      "Never Used (New)        4017\n",
      "Used - Poor             3514\n",
      "Etat moyen               437\n",
      "Average Condition        294\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Price Statistics by Condition:\n",
      "                       count           mean           std      min       25%  \\\n",
      "LAPTOP_CONDITION                                                               \n",
      "Average Condition      294.0   61658.159864  6.352017e+04   5000.0   25000.0   \n",
      "Bon √©tat              7057.0  175193.001926  6.618823e+06     -1.0   15000.0   \n",
      "Etat moyen             437.0   68165.118535  3.185965e+05     -1.0    6000.0   \n",
      "Etat neuf             7723.0  115652.881250  4.438622e+05     -1.0   43000.0   \n",
      "Good Condition        5184.0   88023.600828  5.899833e+04   9000.0   50000.0   \n",
      "Neuf jamais utilis√©   4897.0  178105.198775  5.286567e+05     -1.0   85000.0   \n",
      "Never Used (New)      4017.0  189707.515559  1.221913e+05  13050.0  115000.0   \n",
      "New                   4806.0  242242.977403  7.038109e+05     -1.0  118000.0   \n",
      "Used - Fair           4602.0   86535.046893  5.853025e+04      2.0   62000.0   \n",
      "Used - Good          10914.0  130092.366217  7.646758e+05     -1.0   72000.0   \n",
      "Used - Poor           3514.0   48987.328913  3.536883e+04     -1.0   32000.0   \n",
      "\n",
      "                          50%       75%          max  \n",
      "LAPTOP_CONDITION                                      \n",
      "Average Condition     44999.5   72750.0     550000.0  \n",
      "Bon √©tat              56000.0   92000.0  550178123.0  \n",
      "Etat moyen            25000.0   50000.0    4444444.0  \n",
      "Etat neuf             78000.0  125000.0   17000000.0  \n",
      "Good Condition        75000.0  108000.0     585000.0  \n",
      "Neuf jamais utilis√©  145000.0  225000.0   33500000.0  \n",
      "Never Used (New)     159000.0  239000.0    1300000.0  \n",
      "New                  168000.0  255000.0   33500000.0  \n",
      "Used - Fair           72000.0   96000.0    2500000.0  \n",
      "Used - Good           98000.0  137000.0   75000000.0  \n",
      "Used - Poor           45000.0   57000.0     279000.0  \n"
     ]
    }
   ],
   "source": [
    "# Generate cleaning summary statistics\n",
    "print(\"\\nüìà CLEANING SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüéØ Target Features Cleaned:\")\n",
    "print(f\"  ‚Ä¢ PRICE: {len(df_clean)} values validated\")\n",
    "print(f\"  ‚Ä¢ LAPTOP_CONDITION: Standardized to {df_clean['LAPTOP_CONDITION'].nunique()} categories\")\n",
    "print(f\"  ‚Ä¢ LAPTOP_BRAND: {df_clean['LAPTOP_BRAND'].nunique()} unique brands\")\n",
    "print(f\"  ‚Ä¢ LAPTOP_MODEL: {df_clean['LAPTOP_MODEL'].nunique()} unique models\")\n",
    "print(f\"  ‚Ä¢ POST_YEAR: Range {df_clean['POST_YEAR'].min()}-{df_clean['POST_YEAR'].max()}\")\n",
    "print(f\"  ‚Ä¢ POST_MONTH: Range {df_clean['POST_MONTH'].min()}-{df_clean['POST_MONTH'].max()}\")\n",
    "\n",
    "print(f\"\\nüìä Top 10 Brands:\")\n",
    "print(df_clean['LAPTOP_BRAND'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nüìä Condition Distribution:\")\n",
    "print(df_clean['LAPTOP_CONDITION'].value_counts())\n",
    "\n",
    "print(f\"\\nüìä Price Statistics by Condition:\")\n",
    "print(df_clean.groupby('LAPTOP_CONDITION')['PRICE'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üíæ EXPORT COMPLETED\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Cleaned dataset saved as: full_merged_dataset_CLEANED.csv\n",
      "üìä Total rows: 53,445\n",
      "üìä Total columns: 20\n",
      "\n",
      "üéØ Dataset is now ML-ready!\n",
      "\n",
      "üìã Next steps:\n",
      "  1. Load cleaned dataset for modeling\n",
      "  2. Perform feature engineering if needed\n",
      "  3. Build price prediction model\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned dataset\n",
    "output_filename = 'full_merged_dataset_CLEANED.csv'\n",
    "df_clean.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üíæ EXPORT COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚úÖ Cleaned dataset saved as: {output_filename}\")\n",
    "print(f\"üìä Total rows: {len(df_clean):,}\")\n",
    "print(f\"üìä Total columns: {len(df_clean.columns)}\")\n",
    "print(f\"\\nüéØ Dataset is now ML-ready!\")\n",
    "print(f\"\\nüìã Next steps:\")\n",
    "print(f\"  1. Load cleaned dataset for modeling\")\n",
    "print(f\"  2. Perform feature engineering if needed\")\n",
    "print(f\"  3. Build price prediction model\")\n",
    "print(f\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of cleaned data\n",
    "print(\"\\nüìã Sample of Cleaned Data (First 10 rows):\")\n",
    "print(\"=\"*70)\n",
    "df_clean[target_features].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison: Before vs After\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä BEFORE vs AFTER COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for feature in target_features:\n",
    "    # Original missing\n",
    "    orig_nan = df[feature].isna().sum()\n",
    "    if df[feature].dtype == 'object':\n",
    "        orig_placeholder = (df[feature] == 'NeedToBeFilled').sum()\n",
    "        orig_total = orig_nan + orig_placeholder\n",
    "    else:\n",
    "        orig_total = orig_nan\n",
    "    \n",
    "    orig_pct = (orig_total / len(df)) * 100\n",
    "    \n",
    "    # Cleaned missing\n",
    "    clean_nan = df_clean[feature].isna().sum()\n",
    "    if df_clean[feature].dtype == 'object':\n",
    "        clean_placeholder = df_clean[feature].isin(['NeedToBeFilled', 'Unknown', 'NEEDTOBEFILLED', 'UNKNOWN']).sum()\n",
    "        clean_total = clean_nan + clean_placeholder\n",
    "    else:\n",
    "        clean_total = clean_nan\n",
    "    \n",
    "    clean_pct = (clean_total / len(df_clean)) * 100\n",
    "    \n",
    "    improvement = orig_pct - clean_pct\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Feature': feature,\n",
    "        'Before (Missing)': f\"{orig_total:,} ({orig_pct:.2f}%)\",\n",
    "        'After (Missing)': f\"{clean_total:,} ({clean_pct:.2f}%)\",\n",
    "        'Improvement': f\"{improvement:.2f}%\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ DATA CLEANING MISSION ACCOMPLISHED!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
